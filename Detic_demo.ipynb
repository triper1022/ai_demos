{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNz-yh2HFz_G"
      },
      "source": [
        "GitHub  \n",
        "https://paperswithcode.com/paper/detecting-twenty-thousand-classes-using-image  \n",
        "論文  \n",
        "https://arxiv.org/abs/2201.02605v2  \n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/kaz12tech/ai_demos/blob/master/detecting_demo.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIyC-kLNGZiQ"
      },
      "source": [
        "# ランタイムの設定\n",
        "「ランタイム」→「ランタイムのタイプを変更」→「ハードウェアアクセラレータ」をGPUに変更"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amOVuN1yGsZI"
      },
      "source": [
        "# 実行方法\n",
        "「ランタイム」→「すべてのセルを実行」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKo4CcvmGwJ-"
      },
      "source": [
        "# 環境セットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkUERJOlMLMG"
      },
      "source": [
        "## Cudaバージョンの確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRk0k-ESMODM",
        "outputId": "e37c9643-e9eb-4ff5-e83b-e93358914dd4"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER3MHQOPhq9A"
      },
      "source": [
        "## Pytorchバージョンの変更\n",
        "Deticとの比較対象であるCLIP-ODSがtorch-1.7.1対応のため"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgf_mruWMmXt",
        "outputId": "21fdbb4c-cf38-42f3-ef7b-db0576cfe03b"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip > /dev/null\n",
        "!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex > /dev/null\n",
        "!pip install clip-ods==0.0.1rc2 > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7-BbkFcGxSh"
      },
      "source": [
        "## Pytorchバージョンの確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfPfm0f4FzgM",
        "outputId": "b01ebbd0-0770-47f7-d5fb-eb317f796557"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4o2raKjGeo4"
      },
      "source": [
        "## detectron2をインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lqdZSUZjGd0s",
        "outputId": "4281ce31-07cb-49df-e7cc-f3699adcf70e"
      },
      "outputs": [],
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V14jcibzG4mK"
      },
      "source": [
        "## GitHubからコードをclone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZOSKqCVG223",
        "outputId": "194ed55e-7bd6-4549-bb93-30bf3413c370"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "\n",
        "# GitHubからcode clone\n",
        "!git clone https://github.com/facebookresearch/Detic.git --recurse-submodules\n",
        "%cd Detic\n",
        "# Deticの動作に必要なライブラリをインストール\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H439Q2e3r4QE"
      },
      "source": [
        "## セットアップ\n",
        "ライブラリをインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV_3pb2UHmC4"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import sys\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# Detic libraries\n",
        "sys.path.insert(0, 'third_party/CenterNet2/projects/CenterNet2/')\n",
        "from centernet.config import add_centernet_config\n",
        "from detic.config import add_detic_config\n",
        "from detic.modeling.utils import reset_cls_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv17jGxDr4QH"
      },
      "source": [
        "## 学習済みモデルのダウンロード\n",
        "検出器の定義と学習済みモデルのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbtgXuNFHppz",
        "outputId": "74dc4de4-baf0-40f3-d95b-8e1cfd2a85cf"
      },
      "outputs": [],
      "source": [
        "# Build the detector and download our pretrained weights\n",
        "cfg = get_cfg()\n",
        "add_centernet_config(cfg)\n",
        "add_detic_config(cfg)\n",
        "cfg.merge_from_file(\"configs/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.yaml\")\n",
        "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/detic/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "cfg.MODEL.ROI_BOX_HEAD.ZEROSHOT_WEIGHT_PATH = 'rand'\n",
        "cfg.MODEL.ROI_HEADS.ONE_CLASS_PER_PROPOSAL = True # For better visualization purpose. Set to False for all classes.\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcAu2AXkr4QL"
      },
      "source": [
        "## テスト画像のセットアップ\n",
        "検出対象のファイルをアップロード  \n",
        "  \n",
        "使用画像  \n",
        "https://pixabay.com/ja/photos/%e5%8b%95%e7%89%a9-%e7%8a%ac-%e7%8c%ab-%e5%ad%90%e7%8c%ab-%e5%ad%90%e7%8a%ac-2222007/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "b2G12FE3MbKt",
        "outputId": "4df182e7-73ba-44ed-e21b-c3cd57ff0309"
      },
      "outputs": [],
      "source": [
        "%cd /content/Detic\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "uploaded = list(uploaded.keys())\n",
        "print(uploaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdtYE4laIvGM"
      },
      "source": [
        "## カスタムクラスによる物体検出\n",
        "入力されたキーワードに該当する物体を検出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Afh8uWQFO7d_",
        "outputId": "b380e2cd-5968-4f4a-da82-89de79f9185b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "from detic.modeling.text.text_encoder import build_text_encoder\n",
        "def get_clip_embeddings(vocabulary, prompt='a '):\n",
        "    text_encoder = build_text_encoder(pretrain=True)\n",
        "    text_encoder.eval()\n",
        "    texts = [prompt + x for x in vocabulary]\n",
        "    emb = text_encoder(texts).detach().permute(1, 0).contiguous().cpu()\n",
        "    return emb\n",
        "\n",
        "vocabulary = 'custom'\n",
        "metadata = MetadataCatalog.get(\"__unused\")\n",
        "\n",
        "#@title 検出設定\n",
        "#@markdown 検出対象の名称を英語で入力してください。\\\n",
        "#@markdown 複数検出する場合','で区切ってください。例) cat,dog\n",
        "detect_target = 'Dog,Cat' #@param {type:\"string\"}\n",
        "\n",
        "metadata.thing_classes = detect_target.split(',')\n",
        "\n",
        "classifier = get_clip_embeddings(metadata.thing_classes)\n",
        "num_classes = len(metadata.thing_classes)\n",
        "reset_cls_test(predictor.model, classifier, num_classes)\n",
        "\n",
        "for file in uploaded:\n",
        "  im = cv2.imread(file)\n",
        "\n",
        "  # Reset visualization threshold\n",
        "  #@markdown 表示するスコアの閾値を設定してください。min:0, max:1.0\n",
        "  output_score_threshold = 0.5 #@param {type:\"slider\", min:0, max:1.0, step:0.1}\n",
        "  for cascade_stages in range(len(predictor.model.roi_heads.box_predictor)):\n",
        "    predictor.model.roi_heads.box_predictor[cascade_stages].test_score_thresh = output_score_threshold\n",
        "\n",
        "  # Run model and show results\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:, :, ::-1], metadata)\n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "  cv2.imwrite(\"detit_\"+file, out.get_image()[:, :, ::-1])\n",
        "\n",
        "del metadata.thing_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDpzJhGVI5ig"
      },
      "source": [
        "## 学習済みラベルによる物体検出\n",
        "LVIS、Objects365、OpenImages、Cocoデータセットの学習したラベルで物体検出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjzgDXDssY_g"
      },
      "source": [
        "ボキャブラリ(検出用のラベル)を設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2N0lmrpH_q-",
        "outputId": "2a703bc2-6a23-4f5e-c3f3-b0d7678fd1e8"
      },
      "outputs": [],
      "source": [
        "# Setup the model's vocabulary using build-in datasets\n",
        "\n",
        "BUILDIN_CLASSIFIER = {\n",
        "    'lvis': 'datasets/metadata/lvis_v1_clip_a+cname.npy',\n",
        "    'objects365': 'datasets/metadata/o365_clip_a+cnamefix.npy',\n",
        "    'openimages': 'datasets/metadata/oid_clip_a+cname.npy',\n",
        "    'coco': 'datasets/metadata/coco_clip_a+cname.npy',\n",
        "}\n",
        "\n",
        "BUILDIN_METADATA_PATH = {\n",
        "    'lvis': 'lvis_v1_val',\n",
        "    'objects365': 'objects365_v2_val',\n",
        "    'openimages': 'oid_val_expanded',\n",
        "    'coco': 'coco_2017_val',\n",
        "}\n",
        "\n",
        "# change to 'lvis', 'objects365', 'openimages', or 'coco'\n",
        "#@title 適用するラベルを選択してください。\n",
        "vocabulary = 'openimages' #@param [\"lvis\", \"objects365\", \"openimages\", \"coco\"] {allow-input: false}\n",
        "metadata = MetadataCatalog.get(BUILDIN_METADATA_PATH[vocabulary])\n",
        "classifier = BUILDIN_CLASSIFIER[vocabulary]\n",
        "num_classes = len(metadata.thing_classes)\n",
        "reset_cls_test(predictor.model, classifier, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLa5cchxsm1R"
      },
      "source": [
        "ボキャブラリに設定した物体を全て検出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "xogCpU-tslsM",
        "outputId": "c55dc7a4-2e9f-4962-fda5-bf445df45341"
      },
      "outputs": [],
      "source": [
        "for file in uploaded:\n",
        "  im = cv2.imread(file)\n",
        "\n",
        "  # Reset visualization threshold\n",
        "  output_score_threshold = 0.3\n",
        "  for cascade_stages in range(len(predictor.model.roi_heads.box_predictor)):\n",
        "    predictor.model.roi_heads.box_predictor[cascade_stages].test_score_thresh = output_score_threshold\n",
        "\n",
        "  # Run model and show results\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:, :, ::-1], metadata)\n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImwDbb5DLJFy"
      },
      "source": [
        "# CLIP-ODSのセットアップ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4hFeNnNUp8"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlXhDtd6LMYt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from clip_ods import clip, CLIPDetectorV1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txxmNLclRCwV"
      },
      "source": [
        "## モデルをロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQbJGVHFNSKo",
        "outputId": "3c889497-51a7-4ffb-c009-61cd3e6b8594"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')\n",
        "model, preprocess = clip.load(\"RN50x4\", device=device)  # \"ViT-B/32\",\"RN50\",\"RN101\",\"RN50x4\"\n",
        "clip_detector = CLIPDetectorV1(model, preprocess, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ndiVIwNvAO",
        "outputId": "eb50bc93-ade4-4703-f12b-8878e97bf0df"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "img_path = uploaded[0]\n",
        "\n",
        "coords, masks = clip_detector.get_coords_and_masks(Image.open(img_path))\n",
        "anchor_features = clip_detector.get_anchor_features(Image.open(img_path), coords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "LriYaqfcOtVM",
        "outputId": "eacd41e2-9b5a-4b24-b2c2-5dbfb9d5e208"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "img = Image.open(img_path)\n",
        "colour = (0,255,0)\n",
        "\n",
        "result = clip_detector.detect_by_text(\n",
        "  texts=detect_target.split(','),\n",
        "  img=Image.open(img_path),\n",
        "  coords=coords, masks=masks,\n",
        "  anchor_features=anchor_features,\n",
        "  skip_box_thr=output_score_threshold\n",
        ")\n",
        "\n",
        "img = clip_detector.draw(\n",
        "  img, \n",
        "  result,\n",
        "  label=' '.join(s for s in detect_target),\n",
        "  colour=colour,\n",
        "  font_colour=colour,\n",
        "  font_scale=0.5, \n",
        "  font_thickness=1,\n",
        ")\n",
        "\n",
        "\n",
        "plt.figure(num=None, figsize=(8, 8), dpi=120, facecolor='w', edgecolor='k')\n",
        "plt.imshow(img)\n",
        "pil_img = Image.fromarray(img)\n",
        "pil_img.save('clip_ods_' + uploaded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "10-CkmLO22ZV",
        "outputId": "1dec6be4-a72c-465b-8025-8d90c2c7911a"
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"detit_\" + uploaded[0]).convert(\"RGB\")\n",
        "pre_image = Image.open(\"clip_ods_\" + uploaded[0]).convert(\"RGB\")\n",
        "\n",
        "dst = Image.new('RGB', (image.width + pre_image.width, image.height))\n",
        "dst.paste(image, (0, 0))\n",
        "dst.paste(pre_image, (image.width, 0))\n",
        "\n",
        "# 画像の表示\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saEu1ty1ppQo"
      },
      "source": [
        "\n",
        "# CIFAR10のセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfNuBq9UpUZZ"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDV0QSOuqUeA"
      },
      "source": [
        "## testsetをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU_53KHwpstG",
        "outputId": "94faa475-112b-467e-aca4-e3140f4690bd"
      },
      "outputs": [],
      "source": [
        "%cd /content/Detic\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)),\n",
        "     ])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZgdQcf9-Jui"
      },
      "source": [
        "\n",
        "## CIFAR10をtensorからPILに変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ2rfmhlr6U1"
      },
      "outputs": [],
      "source": [
        "def im_convert(tensor):\n",
        "  image = tensor.clone().detach().numpy()\n",
        "  image = image.transpose(1,2,0)\n",
        "  image = image * np.array((0.5,0.5,0.5)) + np.array((0.5,0.5,0.5))\n",
        "  image = image.clip(0,1)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j1HU4cK-YbE"
      },
      "source": [
        "## CIFAR10を表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "oJ2vuf99qcA5",
        "outputId": "0457278a-7eab-409a-805c-a62c61213eb1"
      },
      "outputs": [],
      "source": [
        "# テストデータセット：縦横32ピクセルのRGBの画像が10000枚\n",
        "print(test_dataset.data.shape)\n",
        "print(test_dataset.classes)\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "fig = plt.figure(num=None, figsize=(12, 5), dpi=128, facecolor='w', edgecolor='k')\n",
        "\n",
        "for i in range(32):\n",
        "  ax = fig.add_subplot(4, 8, i+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[i]))\n",
        "  ax.set_title(test_dataset.classes[labels[i].item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-tzTgV_Eau2"
      },
      "source": [
        "## CIFAR10の保存\n",
        "画像フォルダに見立ててアルバムフォルダに画像を保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG5neOtlDBCd",
        "outputId": "7c900582-6025-48a7-bcd9-fe7252cafb41"
      },
      "outputs": [],
      "source": [
        "%cd /content/Detic\n",
        "!mkdir ./albam\n",
        "\n",
        "for i in range(32):\n",
        "  plt.imsave(\n",
        "      \"./albam/\" + str(i) + '_' + test_dataset.classes[labels[i].item()] + \".jpg\",\n",
        "      im_convert(images[i])\n",
        "      )\n",
        "  \n",
        "import glob\n",
        "albams = glob.glob(\"./albam/*.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "Q8Xj1Xmn_opO",
        "outputId": "f8071725-bc1e-4d19-f97b-494398f42133"
      },
      "outputs": [],
      "source": [
        "vocabulary = 'custom'\n",
        "metadata = MetadataCatalog.get(\"__unused\")\n",
        "\n",
        "#@title 検出設定\n",
        "#@markdown 検出対象の名称を英語で入力してください。\\\n",
        "#@markdown 複数検出する場合','で区切ってください。例) cat,dog\n",
        "detect_target = 'Dog' #@param {type:\"string\"}\n",
        "\n",
        "metadata.thing_classes = detect_target.split(',')\n",
        "\n",
        "classifier = get_clip_embeddings(metadata.thing_classes)\n",
        "num_classes = len(metadata.thing_classes)\n",
        "reset_cls_test(predictor.model, classifier, num_classes)\n",
        "\n",
        "detected_list = []\n",
        "not_list = []\n",
        "\n",
        "for file in albams:\n",
        "  im = cv2.imread(file)\n",
        "\n",
        "  # Reset visualization threshold\n",
        "  #@markdown 表示するスコアの閾値を設定してください。min:0, max:1.0\n",
        "  output_score_threshold = 0.5 #@param {type:\"slider\", min:0, max:1.0, step:0.1}\n",
        "  for cascade_stages in range(len(predictor.model.roi_heads.box_predictor)):\n",
        "    predictor.model.roi_heads.box_predictor[cascade_stages].test_score_thresh = output_score_threshold\n",
        "\n",
        "  # Run model and show results\n",
        "  outputs = predictor(im)\n",
        "  # 検出クラスが1以上の場合は検出対象有と判定\n",
        "  if 0 < len(outputs[\"instances\"].pred_classes):\n",
        "    v = Visualizer(im[:, :, ::-1], metadata)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "    detected_list.append(file)\n",
        "  else:\n",
        "    not_list.append(file)\n",
        "\n",
        "del metadata.thing_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glz6GSHDKl_A",
        "outputId": "c2c32c7e-b319-40f9-cb7f-4e41e8f08c66"
      },
      "outputs": [],
      "source": [
        "print(\"以下の画像は\", detect_target, \"が検出されました。\\n\", detected_list)\n",
        "print(\"以下の画像は未検出です。\\n\", not_list)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Detic_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
